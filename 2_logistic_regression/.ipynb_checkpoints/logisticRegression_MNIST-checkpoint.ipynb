{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano \n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "import timeit\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (6, 4)\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (5.0, 4.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Régression Logistique \n",
    "\n",
    "* Classifieur linéaire \n",
    "* $ x^{i} = (x_{1}, x{_2}, ..., x_{m}) $ le vecteur (ligne) d'entrée (nos données), une image par exemple\n",
    "* Paramètres : une matrice $ W $ et un vecteur ligne $ b $  (ici $\\theta = ( \\ W \\ , \\ b \\ )$)\n",
    "* $ y^{i} \\in \\{1 , 2, ..., K\\}$ , $K$ classes possibles ! \n",
    "\n",
    "$$ \\begin{align} \n",
    "P(Y=i|x, W,b) &= softmax_i(x W + b) \\\\\n",
    "& = \\frac{e^{ x W_i + b_i}}{\\sum_j e^{x W_j + b_j}}\n",
    "\\end{align}$$\n",
    "\n",
    "\n",
    "![Softmax function](../resources/softmax.png )\n",
    "\n",
    "\n",
    "On pour un vecteur d'entrée $x$, connaissant les poids $W$ et $b$ : \n",
    "$$y_{pred} = argmax_i P(Y=i|x,W,b)$$\n",
    "\n",
    "\n",
    "\n",
    "Pour plusieurs images, on définit la fonction de coût comme : \n",
    "$$ E(X,Y,\\theta) = - \\sum_{i=1}^N log( P(Y=y^{(i)}|x^{(i)}, \\theta) ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-batches Stochastic Gradient Descent \n",
    "\n",
    "On ne vas pas calculer l'erreur sur tout le dataset, mais seulement sur un mini-batch de données, c'est à dire quelques exemples (~ 100). \n",
    "\n",
    "On va donc avoir un entrainement de la forme : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nos données \n",
    "X = ....\n",
    "Y = ....\n",
    "batch_size = ...\n",
    "\n",
    "n_train_batches = X.shape[0] // batch_size\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    for index in range(n_train_batches):\n",
    "        \n",
    "        X_batch = X[index*batch_size : (index+1)*batch_size]\n",
    "        Y_batch = Y[index*batch_size : (index+1)*batch_size]\n",
    "        loss = f(params, X_batch, Y_batch)\n",
    "        grad_loss_wrt_params = T.grad(.....)\n",
    "        \n",
    "        params = params - learning_rate * d_loss_wrt_params\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intérêts de la descente du gradient par mini-batch :**\n",
    "* \n",
    "* \n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer : classification de carractères manuscrits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Données d'entrainement, de validation et de test (labels inconnus)\n",
    "X_train = np.load('../data/digit-recognizer/X_train.npy')\n",
    "X_valid = np.load('../data/digit-recognizer/X_valid.npy')\n",
    "X_test = np.load('../data/digit-recognizer/X_test.npy')\n",
    "\n",
    "## Les labels \n",
    "Y_train = np.load('../data/digit-recognizer/y_train.npy')\n",
    "Y_valid = np.load('../data/digit-recognizer/y_valid.npy')\n",
    "\n",
    "print(X_train.shape, X_valid.shape, X_test.shape)\n",
    "print(Y_train.shape, Y_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "---------------------------------------\n",
    "Les images sont déjà sous forme de vecteur 28*28 = 784. \n",
    "\n",
    "37,000 données d'entrainement\n",
    "\n",
    "5,000 données de validation, pour mesurer les performances du classifieur \n",
    "\n",
    "28,000 données à labeliser ! \n",
    "\n",
    "images 28 x 28\n",
    "\n",
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classes = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]\n",
    "num_classes = len(classes)\n",
    "samples = 8\n",
    "\n",
    "for y, cls in enumerate(classes):\n",
    "    idxs = np.nonzero([i == y for i in Y_train])\n",
    "    idxs = np.random.choice(idxs[0], samples, replace=False)\n",
    "    for i , idx in enumerate(idxs):\n",
    "        plt_idx = i * num_classes + y + 1\n",
    "        plt.subplot(samples, num_classes, plt_idx)\n",
    "        plt.imshow(X_train[idx].reshape((28, 28)))\n",
    "        plt.axis(\"off\")\n",
    "        if i == 0:\n",
    "            plt.title(cls)\n",
    "        \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Régression Logistique avec Theano\n",
    "\n",
    "### Créer des variables paratgées (shared variables) pour les données \n",
    "\n",
    "Accélère l'entrainement par mini-batch ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_shared =  T.cast(theano.shared(X_train, borrow=True),'float32')\n",
    "Y_train_shared = T.cast(theano.shared(Y_train, borrow=True),'int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paramètres de l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "n_epochs=100\n",
    "batch_size=128\n",
    "\n",
    "n_train_batches = X_train.shape[0] // batch_size\n",
    "\n",
    "# nb de pixels\n",
    "n_in = 28*28\n",
    "\n",
    "#nb de classes\n",
    "n_out = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction du modèle \n",
    "\n",
    "Besoin de 3 variables symboliques : \n",
    "* index, qui représente le numéro du batch en cours pendant l'entrainemen\n",
    "* X, qui représente nos données, sous forme d'une matrice -> **une ligne = une image**\n",
    "* Y, qui repésente nos labels, sous forme d'un vecteur d'entiers \n",
    "\n",
    "\n",
    "Astuces : \n",
    "Il existe de nombreux types de variables symboliques !\n",
    "\n",
    "`T.scalar(), T.matrix(), T.vector()`\n",
    "\n",
    "et les variantes avec i et l, pour `int` et `long`\n",
    "\n",
    "`T.iscalar(), T.lscalar(), ..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = \n",
    "X = \n",
    "Y = \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paramètres entrainables : W et b\n",
    "Qui sont des variables partagées !\n",
    "\n",
    "Astuce pour créer une variable partagée : \n",
    "\n",
    "``` var = theano.shared( value = var_init, name='var', borrow=True)```\n",
    "\n",
    "Où `var_init` est un tableau `numpy.ndarray` avec `dtype = ... `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# W_init = ...\n",
    "W = theano.shared(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# b_init = ...\n",
    "b = theano.shared(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant définir $P(Y=i|x, W,b)$ et $y_{pred}$\n",
    "\n",
    "Rappels : \n",
    "`theano.tensor` contient certainement toutes les fonctions nécessaires ! \n",
    "Certaines, qui sont spécifiques aux réseaux de neuronnes se trouvent dans `theano.tensor.nnet`\n",
    "\n",
    "Attention : `*` ne correspond pas au produit matriciel ! \n",
    "\n",
    "\n",
    "Caisse à outils : \n",
    "```\n",
    "T.dot(A,B)\n",
    "T.argmin(A,axis=...) , T.argmax(A,axis=...)\n",
    "T.nnet.softmax(A)\n",
    "T.mean(A) -> Si A est un vecteur, T.mean retourne une variable symbolique scalaire \n",
    "T.neq(r,t)\n",
    "T.log()\n",
    "T.arange()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# une matrice, où le i-eme vecteur ligne est de taille K et correspond aux probabilités que l'image de la ligne i\n",
    "# de la matrice X appartiennent aux K classes !\n",
    "p_y_given_x = \n",
    "\n",
    "# un vecteur colonne, où l'élément i correspond à la classe prédite pour l'image de la ligne i de la matrice X ! \n",
    "y_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# variable symbolique scalaire, comprise entre 0 et 1, correspondant au taux d'erreur de prédiction\n",
    "# pour les images de la matrice X\n",
    "errors = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Variable symbolique scalaire\n",
    "# - log-vraisemblance \n",
    "# première étape : matrice log-probabilité \n",
    "\n",
    "LP = \n",
    "\n",
    "# ne garder que les log-probabilités voulues : \n",
    "\n",
    "cost = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour rappel : \n",
    "$$ E(X,Y,\\theta) = - \\sum_{i=1}^N log( P(Y=y^{(i)}|x^{(i)}, \\theta) ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Petit rappel Numpy \n",
    "\n",
    " $$ A =\\begin{pmatrix}\n",
    "     a_{0,0} & a_{0,1} & \\cdots & a_{0,K-1} \\\\\n",
    "     a_{1,0} & a_{1,1} & \\cdots & a_{1,K-1} \\\\\n",
    "     \\vdots  & \\vdots  & \\ddots & \\vdots \\\\\n",
    "     a_{n-1,0} & a_{n-1,1} & \\cdots & a_{n-1,K-1}   \n",
    "\\end{pmatrix} $$\n",
    "\n",
    "Sur chaque ligne $i$, on veut la valeur de la colonne d'indice $b_i$, de façon à former un vecteur.\n",
    "\n",
    "Dans notre cas, sur la matrice des log-probabilités $LP$, on veut la valeur de colonne d'indice $y^{(i)}$, pour la ligne $i$, correspondant à l'exemle $x^{(i)}$\n",
    "\n",
    "\n",
    "Il existe une astuce Numpy pour faire ça en une ligne ! \n",
    "\n",
    "```A[ liste_indices_lignes, liste_indices_colonnes ]```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A = np.array([[ 0.,  1.,  0.,  0.,  0.],\n",
    "       [ 0.,  0.,  0.,  1.,  0.],\n",
    "       [ 0.,  1.,  0.,  0.,  0.],\n",
    "       [ 1.,  0.,  0.,  0.,  0.],\n",
    "       [ 0.,  0.,  0.,  0.,  1.]], dtype='float32')\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "L = range(A.shape[0])\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "C = [1,3,1,0,4]\n",
    "\n",
    "A[L,C]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On peut passer à la compilation de différentes fonctions \n",
    "\n",
    "- Une fonction pour évaluer le modèle, `validation_model`, qui devra calculer le taux d'erreur sur les données de validation \n",
    "\n",
    "- Une fonction pour appliquer le modèle, `test_model`, qui va prédire les classes pour chaque image sur les données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "validation_model = theano.function(\n",
    "        inputs=[....],\n",
    "        outputs=e....\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "test_model = theano.function(\n",
    "        inputs=[...],\n",
    "        outputs= ....\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule les gradients selon les paramètres du système :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g_W = ....\n",
    "g_b = ....\n",
    "\n",
    "  \n",
    "updates = [.....]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction `train_model`, calcul le coût (- log-vraisemblance) du mini-batch d'indice `index`, et met à jour à les paramètres $W$ et $b$ : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model = theano.function(\n",
    "        inputs=[....],\n",
    "        outputs=....,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: ....,\n",
    "            y: ....\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_validation_loss = np.inf\n",
    "validation_frequency = 500\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "for epoch in range(n_epochs):\n",
    "    for minibatch_index in range(n_train_batches):\n",
    "        \n",
    "        minibatch_avg_cost = train_model(minibatch_index)\n",
    "            \n",
    "        # iteration number\n",
    "        iter = (epoch) * n_train_batches + minibatch_index\n",
    "\n",
    "        if (iter + 1) % validation_frequency == 0:\n",
    "            this_validation_loss = validation_model(X_valid,y_valid.astype('int32'))*100.\n",
    "\n",
    "            pylab.plot([iter], [this_validation_loss], 'bo', label='validation_loss')\n",
    "            IPython.display.clear_output(wait=True)\n",
    "            IPython.display.display(pylab.gcf())\n",
    "        \n",
    "            \n",
    "            if this_validation_loss < best_validation_loss:\n",
    "                best_validation_loss = this_validation_loss\n",
    "\n",
    "end_time = timeit.default_timer()\n",
    "\n",
    "print(( 'Entrainement fini : %f %%') % (best_validation_loss * 100.))\n",
    "    \n",
    "print('en %d secondes, avec %f epochs/sec' % ((end_time - start_time), 1. * epoch / (end_time - start_time)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "On peut maintenant passer à la prédiction : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = test_model(X_test)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pour écrire le fichier .csv pour soumettre ses résultats sur Kaggle ! \n",
    "\n",
    "out_file = open(\"predictions_DIGIT-RECOGNIZER.csv\", \"w\")\n",
    "out_file.write(\"ImageId,Label\\n\")\n",
    "for i in range(len(predictions)):\n",
    "    out_file.write(str(i+1) + \",\" + str(int(predictions[i])) + \"\\n\")\n",
    "out_file.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
